import { Callout, Card, Cards, Steps, Tabs } from "nextra/components";
import UniversalTabs from "@/components/UniversalTabs";

# Managed Compute

<Callout type="info">
  This feature is currently in beta and may be subject to change.
</Callout>

## Overview

Hatchet Managed Compute lets you define and manage compute resources directly in your code. This guide shows you how to configure compute instances, create workflows, and manage workers using the Hatchet SDK.

This guide assumes you are already familiar with the basics of Hatchet and have a local workflow running using Docker. If you are not in this state, please see the [Getting Started Guide](../quickstart_cloud.mdx) and [Docker Guide](./dockerizing-workers.mdx).

<UniversalTabs key="worker">
  <Tabs.Tab>

## Basic Configuration

### Compute Configuration

The `Compute` class allows you to define resource requirements for your workload directly in your Python code. You can define multiple compute configurations to use in your workflows on a step-by-step basis. This allows you to easily optimize your compute resources for different parts of your workflow.

```python
from hatchet_sdk.compute import Compute

# Define a default compute configuration
default_compute = Compute(
    cpu_kind="shared",    # CPU type: "shared" or "performance"
    cpus=2,              # Number of CPU cores
    memory_mb=1024,      # Memory allocation in MB
    num_replicas=2,      # Number of instances
    regions=["ewr"]      # Deployment regions
)

# Define a basic compute configuration
basic = Compute(
    cpu_kind="shared",
    cpus=1,
    memory_mb=1024,
    num_replicas=1,
    regions=["ewr"]
)
```

For a full list of configuration options, see the [Compute API documentation](../../compute/cpu.mdx#basic-configuration).

## GPU Support

<Callout type="warning">
  GPU compute has limited region support and constraints. [See the GPU docs for
  more information](../../compute/gpu.mdx).
</Callout>

Hatchet Managed Compute supports GPU instances. You can define GPU compute configurations in the same way as CPU configurations, but with the addition of the `gpu` parameter.

```python
gpu_compute = Compute(
    cpu_kind="shared",
    gpu_kind="a100",
    gpus=1,
    cpus=1,
    memory_mb=1024,
    num_replicas=1,
    regions=["ewr"],
)
```

For a full list of configuration options, see the [Compute API documentation](../../compute/infra-as-code.mdx#gpu).

## Defining Compute Requirements in Workflows

### Workflow Definition

Use compute configuration can then be passed to the `step` decorator to define compute requirements for each step in your workflow.

```python
from hatchet_sdk import Context, Hatchet

hatchet = Hatchet()

@hatchet.workflow(on_events=["user:create"])
class ManagedWorkflow:
    @hatchet.step(
        timeout="11s",
        retries=3,
        compute=default_compute
    )
    def step1(self, context: Context):
        print("executed step1")
        time.sleep(10)
        return {
            "step1": "step1",
        }

    @hatchet.step(
        timeout="11s",
        retries=3,
        compute=basic
    )
    def step2(self, context: Context):
        print("executed step2")
        time.sleep(10)
        return {
            "step2": "step2",
        }
```

## Worker Management

### Setting Up Workers

Configure and start workers to execute your workflows as you would normally do with any other Hatchet worker:

```python
def main():
    # Create workflow instance
    workflow = ManagedWorkflow()

    # Initialize worker with max runs limit
    worker = hatchet.worker("test-worker", max_runs=1)

    # Register workflow with worker
    worker.register_workflow(workflow)

    # Start the worker
    worker.start()
```

A complete example of a workflow that uses managed compute can be found [here](https://github.com/hatchet-dev/managed-compute-examples/tree/main/python).

  </Tabs.Tab>
  <Tabs.Tab>

## Basic Configuration

### Compute Configuration

Hatchet provides TypeScript interfaces for defining compute requirements. You can create multiple compute configurations to use in your workflows on a step-by-step basis, allowing you to optimize resources for different parts of your workflow.

```typescript
import { SharedCPUCompute } from "@hatchet-dev/typescript-sdk/clients/worker/compute/compute-config";
import { ManagedWorkerRegion } from "@hatchet-dev/typescript-sdk/clients/rest/generated/cloud/data-contracts";

// Define a basic compute configuration
const basicCompute: SharedCPUCompute = {
  cpuKind: "shared",
  memoryMb: 1024,
  numReplicas: 1,
  cpus: 1,
  regions: [ManagedWorkerRegion.Ewr],
};

// Define a more powerful compute configuration
const performanceCompute: PerformanceCPUCompute = {
  cpuKind: "performance",
  memoryMb: 2048,
  numReplicas: 2,
  cpus: 2,
  regions: [ManagedWorkerRegion.Ewr],
};
```

For a full list of configuration options, see the [Compute API documentation](../../compute/cpu.mdx#basic-configuration).

## GPU Support

<Callout type="warning">
  GPU compute has limited region support and constraints. [See the GPU docs for
  more information](../../compute/gpu.mdx).
</Callout>

Hatchet Managed Compute supports GPU instances. You can define GPU compute configurations using the `GPUCompute` interface:

```typescript
import { GPUCompute } from "@hatchet-dev/typescript-sdk/clients/worker/compute/compute-config";

const gpuCompute: GPUCompute = {
  cpuKind: "shared",
  gpuKind: "l40s",
  memoryMb: 1024,
  numReplicas: 1,
  cpus: 2,
  gpus: 1,
  regions: [ManagedWorkerRegion.Ewr],
};
```

For a full list of GPU configuration options, see the [Compute API documentation](../../compute/infra-as-code.mdx#gpu).

## Defining Workflows with Compute Requirements

The compute configuration can be specified for each step in your workflow:

```typescript
import Hatchet, { Workflow } from "@hatchet-dev/typescript-sdk";

const hatchet = Hatchet.init();

const workflow: Workflow = {
  id: "managed-workflow",
  description: "Workflow with managed compute",
  on: {
    event: "user:create",
  },
  steps: [
    {
      name: "step1",
      compute: basicCompute,
      run: async (ctx) => {
        console.log("Executing step1 with basic compute");
        return { result: "Step 1 complete" };
      },
    },
    {
      name: "step2",
      parents: ["step1"],
      compute: gpuCompute,
      run: async (ctx) => {
        const step1Result = ctx.stepOutput("step1");
        console.log("Executing step2 with GPU compute after", step1Result);
        return { result: "Step 2 complete" };
      },
    },
  ],
};
```

## Worker Management

### Setting Up Workers

Configure and start workers to execute your workflows:

```typescript
async function main() {
  // Initialize worker
  const worker = await hatchet.worker("managed-worker");

  // Register workflow
  await worker.registerWorkflow(workflow);

  // Start the worker
  worker.start();
}

main();
```

## Complete Example

Here's a complete example of a workflow using different compute configurations:

```typescript
import Hatchet, { Workflow } from "@hatchet-dev/typescript-sdk";
import { ManagedWorkerRegion } from "@hatchet-dev/typescript-sdk/clients/rest/generated/cloud/data-contracts";
import {
  GPUCompute,
  SharedCPUCompute,
} from "@hatchet-dev/typescript-sdk/clients/worker/compute/compute-config";

const hatchet = Hatchet.init();

// Define compute configurations
const cpuCompute: SharedCPUCompute = {
  cpuKind: "shared",
  memoryMb: 1024,
  numReplicas: 1,
  cpus: 1,
  regions: [ManagedWorkerRegion.Ewr],
};

const gpuCompute: GPUCompute = {
  cpuKind: "shared",
  gpuKind: "l40s",
  memoryMb: 1024,
  numReplicas: 1,
  cpus: 2,
  gpus: 1,
  regions: [ManagedWorkerRegion.Ewr],
};

// Define workflow
const workflow: Workflow = {
  id: "simple-workflow",
  description: "Mixed compute workflow example",
  on: {
    event: "user:create",
  },
  steps: [
    {
      name: "step1",
      compute: cpuCompute,
      run: async (ctx) => {
        console.log("executed step1!");
        return { step1: "step1 results!" };
      },
    },
    {
      name: "step2",
      parents: ["step1"],
      compute: gpuCompute,
      run: (ctx) => {
        console.log(
          "executed step2 after step1 returned ",
          ctx.stepOutput("step1"),
        );
        return { step2: "step2 results!" };
      },
    },
  ],
};

// Start worker
async function main() {
  const worker = await hatchet.worker("managed-worker");
  await worker.registerWorkflow(workflow);
  worker.start();
}

main();
```

A complete example of a workflow that uses managed compute can be found [here](https://github.com/hatchet-dev/managed-compute-examples/tree/main/typescript).

  </Tabs.Tab>
  <Tabs.Tab>
Coming soon
  </Tabs.Tab>
</UniversalTabs>
