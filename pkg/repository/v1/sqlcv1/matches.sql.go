// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.24.0
// source: matches.sql

package sqlcv1

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

type CreateMatchConditionsParams struct {
	V1MatchID         int64                  `json:"v1_match_id"`
	TenantID          pgtype.UUID            `json:"tenant_id"`
	EventType         V1EventType            `json:"event_type"`
	EventKey          string                 `json:"event_key"`
	EventResourceHint pgtype.Text            `json:"event_resource_hint"`
	ReadableDataKey   string                 `json:"readable_data_key"`
	OrGroupID         pgtype.UUID            `json:"or_group_id"`
	Expression        pgtype.Text            `json:"expression"`
	Action            V1MatchConditionAction `json:"action"`
	IsSatisfied       bool                   `json:"is_satisfied"`
	Data              []byte                 `json:"data"`
}

const createMatchesForSignalTriggers = `-- name: CreateMatchesForSignalTriggers :many
WITH input AS (
    SELECT
        tenant_id, kind, signal_target_id, signal_key
    FROM
        (
            SELECT
                unnest($1::uuid[]) AS tenant_id,
                unnest(cast($2::text[] as v1_match_kind[])) AS kind,
                unnest($3::bigint[]) AS signal_target_id,
                unnest($4::text[]) AS signal_key
        ) AS subquery
)
INSERT INTO v1_match (
    tenant_id,
    kind,
    signal_target_id,
    signal_key
)
SELECT
    i.tenant_id,
    i.kind,
    i.signal_target_id,
    i.signal_key
FROM
    input i
RETURNING
    id, tenant_id, kind, is_satisfied, signal_target_id, signal_key, trigger_dag_id, trigger_dag_inserted_at, trigger_step_id, trigger_external_id, trigger_existing_task_id
`

type CreateMatchesForSignalTriggersParams struct {
	Tenantids       []pgtype.UUID `json:"tenantids"`
	Kinds           []string      `json:"kinds"`
	Signaltargetids []int64       `json:"signaltargetids"`
	Signalkeys      []string      `json:"signalkeys"`
}

func (q *Queries) CreateMatchesForSignalTriggers(ctx context.Context, db DBTX, arg CreateMatchesForSignalTriggersParams) ([]*V1Match, error) {
	rows, err := db.Query(ctx, createMatchesForSignalTriggers,
		arg.Tenantids,
		arg.Kinds,
		arg.Signaltargetids,
		arg.Signalkeys,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*V1Match
	for rows.Next() {
		var i V1Match
		if err := rows.Scan(
			&i.ID,
			&i.TenantID,
			&i.Kind,
			&i.IsSatisfied,
			&i.SignalTargetID,
			&i.SignalKey,
			&i.TriggerDagID,
			&i.TriggerDagInsertedAt,
			&i.TriggerStepID,
			&i.TriggerExternalID,
			&i.TriggerExistingTaskID,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getSatisfiedMatchConditions = `-- name: GetSatisfiedMatchConditions :many
WITH input AS (
    SELECT
        match_id, condition_id, data
    FROM
        (
            SELECT
                unnest($1::bigint[]) AS match_id,
                unnest($2::bigint[]) AS condition_id,
                unnest($3::jsonb[]) AS data
        ) AS subquery
), locked_conditions AS (
    SELECT
        m.v1_match_id,
        m.id,
        i.data
    FROM
        v1_match_condition m
    JOIN
        input i ON i.match_id = m.v1_match_id AND i.condition_id = m.id
    ORDER BY
        m.id
    -- We can afford a SKIP LOCKED because a match condition can only be satisfied by 1 event
    -- at a time
    FOR UPDATE SKIP LOCKED
), updated_conditions AS (
    UPDATE
        v1_match_condition
    SET
        is_satisfied = TRUE,
        data = c.data
    FROM
        locked_conditions c
    WHERE
        (v1_match_condition.v1_match_id, v1_match_condition.id) = (c.v1_match_id, c.id)
    RETURNING
        v1_match_condition.v1_match_id, v1_match_condition.id
), distinct_match_ids AS (
    SELECT
        DISTINCT v1_match_id
    FROM
        updated_conditions
)
SELECT
    m.id
FROM
    v1_match m
JOIN
    distinct_match_ids dm ON dm.v1_match_id = m.id
ORDER BY
    m.id
FOR UPDATE
`

type GetSatisfiedMatchConditionsParams struct {
	Matchids     []int64  `json:"matchids"`
	Conditionids []int64  `json:"conditionids"`
	Datas        [][]byte `json:"datas"`
}

// NOTE: we have to break this into a separate query because CTEs can't see modified rows
// on the same target table without using RETURNING.
func (q *Queries) GetSatisfiedMatchConditions(ctx context.Context, db DBTX, arg GetSatisfiedMatchConditionsParams) ([]int64, error) {
	rows, err := db.Query(ctx, getSatisfiedMatchConditions, arg.Matchids, arg.Conditionids, arg.Datas)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []int64
	for rows.Next() {
		var id int64
		if err := rows.Scan(&id); err != nil {
			return nil, err
		}
		items = append(items, id)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const resetMatchConditions = `-- name: ResetMatchConditions :many
WITH input AS (
    SELECT
        match_id, condition_id, data
    FROM
        (
            SELECT
                unnest($1::bigint[]) AS match_id,
                unnest($2::bigint[]) AS condition_id,
                unnest($3::jsonb[]) AS data
        ) AS subquery
), locked_conditions AS (
    SELECT
        m.v1_match_id,
        m.id,
        i.data
    FROM
        v1_match_condition m
    JOIN
        input i ON i.match_id = m.v1_match_id AND i.condition_id = m.id
    ORDER BY
        m.id
    -- We can afford a SKIP LOCKED because a match condition can only be satisfied by 1 event
    -- at a time
    FOR UPDATE SKIP LOCKED
), updated_conditions AS (
    UPDATE
        v1_match_condition
    SET
        is_satisfied = TRUE,
        data = c.data
    FROM
        locked_conditions c
    WHERE
        (v1_match_condition.v1_match_id, v1_match_condition.id) = (c.v1_match_id, c.id)
    RETURNING
        v1_match_condition.v1_match_id, v1_match_condition.id
), distinct_match_ids AS (
    SELECT
        DISTINCT v1_match_id
    FROM
        updated_conditions
)
SELECT
    m.id
FROM
    v1_match m
JOIN
    distinct_match_ids dm ON dm.v1_match_id = m.id
ORDER BY
    m.id
FOR UPDATE
`

type ResetMatchConditionsParams struct {
	Matchids     []int64  `json:"matchids"`
	Conditionids []int64  `json:"conditionids"`
	Datas        [][]byte `json:"datas"`
}

// NOTE: we have to break this into a separate query because CTEs can't see modified rows
// on the same target table without using RETURNING.
func (q *Queries) ResetMatchConditions(ctx context.Context, db DBTX, arg ResetMatchConditionsParams) ([]int64, error) {
	rows, err := db.Query(ctx, resetMatchConditions, arg.Matchids, arg.Conditionids, arg.Datas)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []int64
	for rows.Next() {
		var id int64
		if err := rows.Scan(&id); err != nil {
			return nil, err
		}
		items = append(items, id)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const saveSatisfiedMatchConditions = `-- name: SaveSatisfiedMatchConditions :many
WITH match_counts AS (
    SELECT
        v1_match_id,
        COUNT(DISTINCT CASE WHEN action = 'QUEUE' THEN or_group_id END) AS total_queue_groups,
        COUNT(DISTINCT CASE WHEN is_satisfied AND action = 'QUEUE' THEN or_group_id END) AS satisfied_queue_groups,
        COUNT(DISTINCT CASE WHEN action = 'CANCEL' THEN or_group_id END) AS total_cancel_groups,
        COUNT(DISTINCT CASE WHEN is_satisfied AND action = 'CANCEL' THEN or_group_id END) AS satisfied_cancel_groups,
        COUNT(DISTINCT CASE WHEN action = 'SKIP' THEN or_group_id END) AS total_skip_groups,
        COUNT(DISTINCT CASE WHEN is_satisfied AND action = 'SKIP' THEN or_group_id END) AS satisfied_skip_groups,
        (
            SELECT jsonb_object_agg(action, aggregated_1)
            FROM (
                SELECT action, jsonb_object_agg(readable_data_key, data_array) AS aggregated_1
                FROM (
                    SELECT action, readable_data_key, jsonb_agg(data) AS data_array
                    FROM v1_match_condition sub
                    WHERE sub.v1_match_id = ANY($1::bigint[])
                    AND is_satisfied
                    GROUP BY action, readable_data_key
                ) t
                GROUP BY action
            ) s
        ) AS aggregated_data
    FROM v1_match_condition main
    WHERE v1_match_id = ANY($1::bigint[])
    GROUP BY v1_match_id
), result_matches AS (
    SELECT
        m.id, m.tenant_id, m.kind, m.is_satisfied, m.signal_target_id, m.signal_key, m.trigger_dag_id, m.trigger_dag_inserted_at, m.trigger_step_id, m.trigger_external_id, m.trigger_existing_task_id,
        mc.aggregated_data::jsonb as mc_aggregated_data
    FROM
        v1_match m
    JOIN
        match_counts mc ON m.id = mc.v1_match_id
    WHERE
        (
            mc.total_queue_groups = mc.satisfied_queue_groups
            OR mc.total_cancel_groups = mc.satisfied_cancel_groups
            OR mc.total_skip_groups = mc.satisfied_skip_groups
        )
), deleted_matches AS (
    DELETE FROM
        v1_match
    WHERE
        id IN (SELECT id FROM result_matches)
), locked_conditions AS (
    SELECT
        m.v1_match_id,
        m.id
    FROM
        v1_match_condition m
    JOIN
        result_matches r ON r.id = m.v1_match_id
    ORDER BY
        m.id
    FOR UPDATE
), deleted_conditions AS (
    DELETE FROM
        v1_match_condition
    WHERE
        (v1_match_id, id) IN (SELECT v1_match_id, id FROM locked_conditions)
)
SELECT
    id, tenant_id, kind, is_satisfied, signal_target_id, signal_key, trigger_dag_id, trigger_dag_inserted_at, trigger_step_id, trigger_external_id, trigger_existing_task_id, mc_aggregated_data
FROM
    result_matches
`

type SaveSatisfiedMatchConditionsRow struct {
	ID                    int64              `json:"id"`
	TenantID              pgtype.UUID        `json:"tenant_id"`
	Kind                  V1MatchKind        `json:"kind"`
	IsSatisfied           bool               `json:"is_satisfied"`
	SignalTargetID        pgtype.Int8        `json:"signal_target_id"`
	SignalKey             pgtype.Text        `json:"signal_key"`
	TriggerDagID          pgtype.Int8        `json:"trigger_dag_id"`
	TriggerDagInsertedAt  pgtype.Timestamptz `json:"trigger_dag_inserted_at"`
	TriggerStepID         pgtype.UUID        `json:"trigger_step_id"`
	TriggerExternalID     pgtype.UUID        `json:"trigger_external_id"`
	TriggerExistingTaskID pgtype.Int8        `json:"trigger_existing_task_id"`
	McAggregatedData      []byte             `json:"mc_aggregated_data"`
}

// NOTE: we have to break this into a separate query because CTEs can't see modified rows
// on the same target table without using RETURNING.
// Additionally, since we've placed a FOR UPDATE lock in the previous query, we're guaranteeing
// that only one transaction can update these rows,so this should be concurrency-safe.
func (q *Queries) SaveSatisfiedMatchConditions(ctx context.Context, db DBTX, matchids []int64) ([]*SaveSatisfiedMatchConditionsRow, error) {
	rows, err := db.Query(ctx, saveSatisfiedMatchConditions, matchids)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*SaveSatisfiedMatchConditionsRow
	for rows.Next() {
		var i SaveSatisfiedMatchConditionsRow
		if err := rows.Scan(
			&i.ID,
			&i.TenantID,
			&i.Kind,
			&i.IsSatisfied,
			&i.SignalTargetID,
			&i.SignalKey,
			&i.TriggerDagID,
			&i.TriggerDagInsertedAt,
			&i.TriggerStepID,
			&i.TriggerExternalID,
			&i.TriggerExistingTaskID,
			&i.McAggregatedData,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
